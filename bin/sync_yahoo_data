#!/usr/bin/env python

import sys,os
# Add the root of the repo to the include path.
sys.path.append(os.path.abspath('.'))

import MySQLdb
import argparse
import datetime
import dateutil.relativedelta
import urllib2
import urllib
import json
from sharpefolio import stocks

def parseDateArg(string):
    return datetime.datetime.strptime("%s" % string, "%Y-%m-%d").date()

json_data = open('variables.json')
variables = json.load(json_data)

connection = MySQLdb.connect(
    host   = variables['mysql_host'],
    user   = variables['mysql_user'],
    passwd = variables['mysql_password'],
    db     = variables['mysql_database']
)

# Set up stock mapper
stock_repository = stocks.StockMysqlRepository(connection)
stock_mapper = stocks.StockMapper(stock_repository)

# Set up price mapper
price_repository = stocks.PriceMysqlRepository(connection)
price_mapper = stocks.PriceMapper(price_repository)

parser = argparse.ArgumentParser(description='Sync with the prices from the yahoo finance API.')

yesterday = datetime.datetime.now().date() - datetime.timedelta(days=1)

parser.add_argument('startDate', type=parseDateArg)
parser.add_argument('--endDate', type=parseDateArg, default=yesterday)

args = parser.parse_args()

url = 'http://query.yahooapis.com/v1/public/yql?'
params = {'format': 'json', 'env': 'store://datatables.org/alltableswithkeys', 'q': None}
query = 'select * from yahoo.finance.historicaldata where symbol = "%s" and startDate = "%04d-%02d-1" and endDate = "%04d-%02d-1"'

startDate = args.startDate
endDate = args.endDate

while startDate < endDate:
    newDate = startDate
    newDatePlusOne = newDate + dateutil.relativedelta.relativedelta(months=1)

    result_dir = "logs/%04d-%02d" % (newDate.year, newDate.month)
    # Create any missing directory.
    if not os.path.exists(result_dir):
        os.makedirs(result_dir)

    stocks_collection = stock_mapper.find_all()

    for stock in stocks_collection:
        result_file = "%s/%s.json" % (result_dir, stock.symbol)
        if os.path.exists(result_file):
            result_data = json.load(open(result_file))
            if result_data['ran_perfectly']:
                print '(%d - %s - %04d-%02d) skipping because it already ran' % (stock.id, stock.symbol, newDate.year, newDate.month)
                continue # No need to run again!

        new_result_data = {
            "ran_perfectly": True, # Start with this being a perfect run.
            "errors": [],
        }

        try:
            params['q'] = query % (stock.symbol, newDate.year, newDate.month, newDatePlusOne.year, newDatePlusOne.month)
            print(params['q'])
            result = urllib2.urlopen(url+urllib.urlencode(params))
            data = json.load(result)
        except urllib2.HTTPError, e:
            print 'HTTP Error:', e, url+urllib.urlencode(params)
            raise e
        else:
            if data['query']['results'] == None:
                new_result_data['ran_perfectly'] = False
                new_result_data['errors'].append('(%d) skipping empty result %s for %s' % (stock.id, stock.symbol, newDate.year))
                print '(%d) skipping empty result %s for %s' % (stock.id, stock.symbol, newDate.year)
                # Save the result for this stock.
                with open(result_file, 'w+') as outfile:
                    json.dump(new_result_data, outfile, indent = 4, separators = (',', ': '))
                continue

            for info in data['query']['results']['quote']:
                try:
                    close = info['Adj_Close']
                    date = datetime.datetime.strptime(info['Date'], '%Y-%m-%d')
                    price = stocks.Price(stock.id, date, close, 0)
                    price_mapper.insert(price)
                except Exception, e:
                    new_result_data['ran_perfectly'] = False
                    new_result_data['errors'].append('(%d) error inserting %s for %d (%s)' % (stock.id, stock.symbol, newDate.year, e))
                    print '(%d) error inserting %s for %d (%s)' % (stock.id, stock.symbol, newDate.year, e)
                    pass
                except urllib2.HTTPError, e:
                    new_result_data['ran_perfectly'] = False
                    new_result_data['errors'].append('(%d) HTTP Error %s' % (stock.id, e))
                    print '(%d) HTTP Error %s' % (stock.id, e)
                    raise e
                else:
                    print '(%d) successfully imported %s for %d-%d-%d' % (stock.id, stock.symbol, date.year, date.month, date.day)

        # Save the result for this stock.
        with open(result_file, 'w+') as outfile:
            json.dump(new_result_data, outfile, indent = 4, separators = (',', ': '))

    # Increment the new start date after each month has been synced.
    startDate = newDatePlusOne
